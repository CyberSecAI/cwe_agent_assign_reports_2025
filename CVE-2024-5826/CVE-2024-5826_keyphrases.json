{
  "keyphrases": {
    "rootcause": "lack of a sandbox when executing LLM-generated code",
    "weakness": "prompt injection"
  }
}