{
  "method": "sparse_altterm_weakness_prompt inj",
  "query": "The EmailGPT service contains a prompt injection vulnerability. The service uses an API service that allows a malicious user to inject a direct prompt and take over the service logic. Attackers can exploit the issue by forcing the AI service to leak the standard hard-coded system prompts and/or execute unwanted prompts. When engaging with EmailGPT by submitting a malicious prompt that requests harmful information, the system will respond by providing the requested data. This vulnerability can be exploited by any individual with access to the service.",
  "keyphrases": {
    "weakness": "prompt injection"
  },
  "timestamp": "2025-07-13T20:58:04.550124",
  "results_count": 1,
  "results_summary": [
    {
      "doc_id": "1427",
      "name": "Improper Neutralization of Input Used for LLM Prompting",
      "score": 1000.0
    }
  ]
}