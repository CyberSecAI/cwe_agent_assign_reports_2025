{
  "method": "sparse_base",
  "query": "In the `manim` plugin of binary-husky/gpt_academic, versions prior to the fix, a vulnerability exists due to improper handling of user-provided prompts. The root cause is the execution of untrusted code generated by the LLM without a proper sandbox. This allows an attacker to perform remote code execution (RCE) on the app backend server by injecting malicious code through the prompt.",
  "keyphrases": {
    "base_query": "In the `manim` plugin of binary-husky/gpt_academic, versions prior to the fix, a vulnerability exists due to improper handling of user-provided prompts. The root cause is the execution of untrusted code generated by the LLM without a proper sandbox. This allows an attacker to perform remote code execution (RCE) on the app backend server by injecting malicious code through the prompt."
  },
  "timestamp": "2025-07-13T00:39:38.358597",
  "results_count": 10,
  "results_summary": [
    {
      "doc_id": "94",
      "name": "Improper Control of Generation of Code ('Code Injection')",
      "score": 119.55889553819337
    },
    {
      "doc_id": "138",
      "name": "Improper Neutralization of Special Elements",
      "score": 117.50136707538638
    },
    {
      "doc_id": "1427",
      "name": "Improper Neutralization of Input Used for LLM Prompting",
      "score": 117.40975230801052
    },
    {
      "doc_id": "20",
      "name": "Improper Input Validation",
      "score": 116.33645353194393
    },
    {
      "doc_id": "502",
      "name": "Deserialization of Untrusted Data",
      "score": 115.9398118945715
    }
  ]
}