{
  "method": "sparse_base",
  "query": "In the Linux kernel, the following vulnerability has been resolved xfrm state fix out-of-bounds read during lookup lookup and resize can run in parallel. The xfrm_state_hash_generation seqlock ensures a retry, but the hash functions can observe a hmask value that is too large for the new hlist array. rehash does rcu_assign_pointer(net->xfrm.state_bydst, ndst) [..] net->xfrm.state_hmask = nhashmask While state lookup does h = xfrm_dst_hash(net, daddr, saddr, tmpl->reqid, encap_family) hlist_for_each_entry_rcu(x, net->xfrm.state_bydst + h, bydst) { This is only safe in case the update to state_bydst is larger than net->xfrm.xfrm_state_hmask (or if the lookup function gets serialized via state spinlock again). Fix this by prefetching state_hmask and the associated pointers. The xfrm_state_hash_generation seqlock retry will ensure that the pointer and the hmask will be consistent. The existing helpers, like xfrm_dst_hash(), are now unsafe for RCU side, add lockdep assertions to document that they are only safe for insert side. xfrm_state_lookup_byaddr() uses the spinlock rather than RCU. AFAICS this is an oversight from back when state lookup was converted to RCU, this lock should be replaced with RCU in a future patch.",
  "keyphrases": {
    "base_query": "In the Linux kernel, the following vulnerability has been resolved xfrm state fix out-of-bounds read during lookup lookup and resize can run in parallel. The xfrm_state_hash_generation seqlock ensures a retry, but the hash functions can observe a hmask value that is too large for the new hlist array. rehash does rcu_assign_pointer(net->xfrm.state_bydst, ndst) [..] net->xfrm.state_hmask = nhashmask While state lookup does h = xfrm_dst_hash(net, daddr, saddr, tmpl->reqid, encap_family) hlist_for_each_entry_rcu(x, net->xfrm.state_bydst + h, bydst) { This is only safe in case the update to state_bydst is larger than net->xfrm.xfrm_state_hmask (or if the lookup function gets serialized via state spinlock again). Fix this by prefetching state_hmask and the associated pointers. The xfrm_state_hash_generation seqlock retry will ensure that the pointer and the hmask will be consistent. The existing helpers, like xfrm_dst_hash(), are now unsafe for RCU side, add lockdep assertions to document that they are only safe for insert side. xfrm_state_lookup_byaddr() uses the spinlock rather than RCU. AFAICS this is an oversight from back when state lookup was converted to RCU, this lock should be replaced with RCU in a future patch."
  },
  "timestamp": "2025-07-12T06:58:16.246613",
  "results_count": 10,
  "results_summary": [
    {
      "doc_id": "201",
      "name": "Insertion of Sensitive Information Into Sent Data",
      "score": 261.32879815292773
    },
    {
      "doc_id": "502",
      "name": "Deserialization of Untrusted Data",
      "score": 260.8337655747935
    },
    {
      "doc_id": "674",
      "name": "Uncontrolled Recursion",
      "score": 253.58910493059116
    },
    {
      "doc_id": "770",
      "name": "Allocation of Resources Without Limits or Throttling",
      "score": 253.5207362980918
    },
    {
      "doc_id": "917",
      "name": "Improper Neutralization of Special Elements used in an Expression Language Statement ('Expression Language Injection')",
      "score": 251.83803806812563
    }
  ]
}