{
  "method": "sparse_rootcause_1",
  "query": "A prompt injection vulnerability in the chatbox of Netangular Technologies ChatNet AI Version v1.0 allows attackers to access and exfiltrate all previous and subsequent chat data between the user and the AI assistant via a crafted message.",
  "keyphrases": {
    "rootcause": "prompt injection"
  },
  "timestamp": "2025-07-13T18:44:33.420982",
  "results_count": 10,
  "results_summary": [
    {
      "doc_id": "116",
      "name": "Improper Encoding or Escaping of Output",
      "score": 219.57158660247893
    },
    {
      "doc_id": "1336",
      "name": "Improper Neutralization of Special Elements Used in a Template Engine",
      "score": 205.82056630935816
    },
    {
      "doc_id": "74",
      "name": "Improper Neutralization of Special Elements in Output Used by a Downstream Component ('Injection')",
      "score": 202.05223203114426
    },
    {
      "doc_id": "94",
      "name": "Improper Control of Generation of Code ('Code Injection')",
      "score": 200.2271663628506
    },
    {
      "doc_id": "1427",
      "name": "Improper Neutralization of Input Used for LLM Prompting",
      "score": 197.44119689131932
    }
  ]
}