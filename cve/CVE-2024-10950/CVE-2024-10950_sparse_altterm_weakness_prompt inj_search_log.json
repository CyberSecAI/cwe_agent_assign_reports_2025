{
  "method": "sparse_altterm_weakness_prompt inj",
  "query": "In binary-husky/gpt_academic version <= 3.83, the plugin `CodeInterpreter` is vulnerable to code injection caused by prompt injection. The root cause is the execution of user-provided prompts that generate untrusted code without a sandbox, allowing the execution of parts of the LLM-generated code. This vulnerability can be exploited by an attacker to achieve remote code execution (RCE) on the application backend server, potentially gaining full control of the server.",
  "keyphrases": {
    "weakness": "prompt injection"
  },
  "timestamp": "2025-07-13T00:39:20.526852",
  "results_count": 1,
  "results_summary": [
    {
      "doc_id": "1427",
      "name": "Improper Neutralization of Input Used for LLM Prompting",
      "score": 1000.0
    }
  ]
}