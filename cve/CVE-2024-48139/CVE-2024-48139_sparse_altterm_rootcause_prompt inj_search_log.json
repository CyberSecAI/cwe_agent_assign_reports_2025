{
  "method": "sparse_altterm_rootcause_prompt inj",
  "query": "A prompt injection vulnerability in the chatbox of Blackbox AI v1.3.95 allows attackers to access and exfiltrate all previous and subsequent chat data between the user and the AI assistant via a crafted message.",
  "keyphrases": {
    "rootcause": "prompt injection vulnerability"
  },
  "timestamp": "2025-07-13T18:43:01.254477",
  "results_count": 1,
  "results_summary": [
    {
      "doc_id": "1427",
      "name": "Improper Neutralization of Input Used for LLM Prompting",
      "score": 800.0
    }
  ]
}