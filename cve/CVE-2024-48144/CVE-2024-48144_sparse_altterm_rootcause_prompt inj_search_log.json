{
  "method": "sparse_altterm_rootcause_prompt inj",
  "query": "A prompt injection vulnerability in the chatbox of Fusion Chat Chat AI Assistant Ask Me Anything v1.2.4.0 allows attackers to access and exfiltrate all previous and subsequent chat data between the user and the AI assistant via a crafted message.",
  "keyphrases": {
    "rootcause": "prompt injection"
  },
  "timestamp": "2025-07-13T18:44:13.805362",
  "results_count": 1,
  "results_summary": [
    {
      "doc_id": "1427",
      "name": "Improper Neutralization of Input Used for LLM Prompting",
      "score": 1000.0
    }
  ]
}