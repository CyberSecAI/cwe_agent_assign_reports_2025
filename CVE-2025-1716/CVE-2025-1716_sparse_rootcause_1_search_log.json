{
  "method": "sparse_rootcause_1",
  "query": "picklescan before 0.0.21 does not treat pip as an unsafe global. An attacker could craft a malicious model that uses Pickle to pull in a malicious PyPI package (hosted, for example, on pypi.org or GitHub) via `pip.main()`. Because pip is not a restricted global, the model, when scanned with picklescan, would pass security checks and appear to be safe, when it could instead prove to be problematic.",
  "keyphrases": {
    "rootcause": "picklescan before 0.0.21 does not treat pip as an unsafe global"
  },
  "timestamp": "2025-07-12T09:14:00.178499",
  "results_count": 10,
  "results_summary": [
    {
      "doc_id": "497",
      "name": "Exposure of Sensitive System Information to an Unauthorized Control Sphere",
      "score": 457.4369719173478
    },
    {
      "doc_id": "138",
      "name": "Improper Neutralization of Special Elements",
      "score": 418.5696840631009
    },
    {
      "doc_id": "1333",
      "name": "Inefficient Regular Expression Complexity",
      "score": 418.0313224146784
    },
    {
      "doc_id": "23",
      "name": "Relative Path Traversal",
      "score": 406.9620620570898
    },
    {
      "doc_id": "522",
      "name": "Insufficiently Protected Credentials",
      "score": 404.08604320868585
    }
  ]
}