## Vulnerability Description
In the Linux kernel, the following vulnerability has been resolved io_uring fix possible deadlock in io_register_iowq_max_workers() The io_register_iowq_max_workers() function calls io_put_sq_data(), which acquires the sqd->lock without releasing the uring_lock. Similar to the commit 009ad9f0c6ee (io_uring drop ctx->uring_lock before acquiring sqd->lock), this can lead to a potential deadlock situation. To resolve this issue, the uring_lock is released before calling io_put_sq_data(), and then it is re-acquired after the function call. This change ensures that the locks are acquired in the correct order, preventing the possibility of a deadlock.

### Vulnerability Description Key Phrases
- **rootcause:** **improper lock order**
- **impact:** deadlock
- **product:** Linux kernel
- **component:** io_uring

## CVE Reference Links Content Summary
Based on the provided information, the content is related to CVE-2024-41080.

**Root cause of vulnerability:**
The `io_register_iowq_max_workers()` function in the Linux kernel's io_uring subsystem calls `io_put_sq_data()`, which acquires the `sqd->lock` without releasing the `uring_lock`. This incorrect lock acquisition order can lead to a potential deadlock situation.

**Weaknesses/vulnerabilities present:**
The vulnerability is a deadlock caused by improper lock ordering. Specifically, `uring_lock` is held when trying to acquire `sqd->lock`, whereas `sqd->lock` might be held by another thread trying to acquire `uring_lock`, leading to a deadlock.

**Impact of exploitation:**
Exploitation of this vulnerability can lead to a system deadlock, resulting in a denial of service (DoS).

**Attack vectors:**
The attack vector involves a malicious or compromised process calling the `io_register_iowq_max_workers()` function in a way that triggers the described lock ordering issue.

**Required attacker capabilities/position:**
The attacker needs to be able to make system calls to `io_uring` with the capability to register an IOWQ and set the max workers. This means the attacker must have the ability to execute code on the system.

**Additional details:**
The provided content includes multiple instances of the fix being applied to different kernel versions, all referencing the same root cause and resolution. The fix involves releasing the `uring_lock` before acquiring the `sqd->lock` and then reacquiring it, ensuring the locks are acquired in a correct order.

## Retriever Results

### Top Combined Results

| Rank | CWE ID | Name | Abstraction | Usage  | Retrievers | Individual Scores |
|------|--------|------|-------------|-------|------------|-------------------|
| 1 | 667 | Improper Locking | Class | Allowed-with-Review | sparse | 0.588 |
| 2 | 833 | Deadlock | Base | Allowed | sparse | 0.562 |
| 3 | 362 | Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition') | Class | Allowed-with-Review | sparse | 0.475 |
| 4 | 663 | Use of a Non-reentrant Function in a Concurrent Context | Base | Allowed | sparse | 0.449 |
| 5 | 911 | Improper Update of Reference Count | Base | Allowed | sparse | 0.421 |
| 6 | 1390 | Weak Authentication | Class | Allowed-with-Review | sparse | 0.421 |
| 7 | 122 | Heap-based Buffer Overflow | Variant | Allowed | sparse | 0.420 |
| 8 | 306 | Missing Authentication for Critical Function | Base | Allowed | sparse | 0.416 |
| 9 | 413 | Improper Resource Locking | Base | Allowed | dense | 0.509 |
| 10 | 1265 | Unintended Reentrant Invocation of Non-reentrant Code Via Nested Calls | Base | Allowed | graph | 0.002 |



# Complete CWE Specifications

CWE-667: Improper Locking

CWE-833: Deadlock

CWE-362: Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition')

CWE-663: Use of a Non-reentrant Function in a Concurrent Context

CWE-911: Improper Update of Reference Count

CWE-1390: Weak Authentication

CWE-122: Heap-based Buffer Overflow

CWE-306: Missing Authentication for Critical Function

CWE-413: Improper Resource Locking

CWE-1265: Unintended Reentrant Invocation of Non-reentrant Code Via Nested Calls