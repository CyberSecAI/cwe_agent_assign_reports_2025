{
  "retriever": "sparse",
  "query": "In the Linux kernel, the following vulnerability has been resolvedpowerpc/qspinlock Fix deadlock in MCS queueIf an interrupt occurs in queued_spin_lock_slowpath() after we incrementqnodesp->count and before node->lock is initialized, another CPU mightsee stale lock values in get_tail_qnode(). If the stale lock value happensto match the lock on that CPU, then we write to the next pointer ofthe wrong qnode. This causes a deadlock as the former CPU, once it becomesthe head of the MCS queue, will spin indefinitely until its next pointeris set by its successor in the queue.Running stress-ng on a 16 core (16EC/16VP) shared LPAR, results inoccasional lockups similar to the following $ stress-ng --all 128 --vm-bytes 80% --aggressive \\ --maximize --oomable --verify --syslog \\ --metrics --times --timeout 5m watchdog CPU 15 Hard LOCKUP ...... NIP [c0000000000b78f4] queued_spin_lock_slowpath+0x1184/0x1490 LR [c000000001037c5c] _raw_spin_lock+0x6c/0x90 Call Trace 0xc000002cfffa3bf0 (unreliable) _raw_spin_lock+0x6c/0x90 raw_spin_rq_lock_nested.part.135+0x4c/0xd0 sched_ttwu_pending+0x60/0x1f0 __flush_smp_call_function_queue+0x1dc/0x670 smp_ipi_demux_relaxed+0xa4/0x100 xive_muxed_ipi_action+0x20/0x40 __handle_irq_event_percpu+0x80/0x240 handle_irq_event_percpu+0x2c/0x80 handle_percpu_irq+0x84/0xd0 generic_handle_irq+0x54/0x80 __do_irq+0xac/0x210 __do_IRQ+0x74/0xd0 0x0 do_IRQ+0x8c/0x170 hardware_interrupt_common_virt+0x29c/0x2a0 --- interrupt 500 at queued_spin_lock_slowpath+0x4b8/0x1490 ...... NIP [c0000000000b6c28] queued_spin_lock_slowpath+0x4b8/0x1490 LR [c000000001037c5c] _raw_spin_lock+0x6c/0x90 --- interrupt 500 0xc0000029c1a41d00 (unreliable) _raw_spin_lock+0x6c/0x90 futex_wake+0x100/0x260 do_futex+0x21c/0x2a0 sys_futex+0x98/0x270 system_call_exception+0x14c/0x2f0 system_call_vectored_common+0x15c/0x2ecThe following code flow illustrates how the deadlock occurs.For the sake of brevity, assume that both locks (A and B) arecontended and we call the queued_spin_lock_slowpath() function. CPU0 CPU1 ---- ---- spin_lock_irqsave(A) | spin_unlock_irqrestore(A) | spin_lock(B) | | | ? | id = qnodesp->count++ | (Note that nodes[0].lock == A) | | | ? | Interrupt | (happens before nodes[0].lock = B) | | | ? | spin_lock_irqsave(A) | | | ? | id = qnodesp->count++ | nodes[1].lock = A | | | ? | Tail of MCS queue | | spin_lock_irqsave(A) ? | Head of MCS queue ? | CPU0 is previous tail ? | Spin indefinitely ? (until nodes[1].next != NULL) prev = get_tail_qnode(A, CPU0) | ? prev == &qnodes[CPU0].nodes[0] (as qnodes---truncated---",
  "keyphrases": {
    "rootcause": [
      "A race condition in queued_spin_lock_slowpath() leads to a deadlock. Specifically",
      "an interrupt occurring after incrementing qnodesp->count but before initializing node->lock can cause another CPU to read stale lock values from get_tail_qnode(). If this stale lock value matches the lock on the other CPU",
      "it can result in incorrect next pointer assignment in the MCS queue",
      "causing a deadlock."
    ],
    "weakness": [
      "Race condition due to the lack of proper synchronization between incrementing the qnodesp->count",
      "initializing node->lock in the queued_spin_lock_slowpath() function."
    ]
  },
  "timestamp": "2025-07-12 04:46:55",
  "cve_id": "CVE-2024-46797",
  "result_count": 12,
  "results": [
    {
      "cwe_id": "667",
      "name": "Improper Locking",
      "score": 1074.4331587697034,
      "search_source": "rootcause:an interrupt occurring after incrementing qnodesp->count but before initializing node->lock can cause another CPU to read stale lock values from get_tail_qnode(). If this stale lock value matches the lock on the other CPU"
    },
    {
      "cwe_id": "833",
      "name": "Deadlock",
      "score": 1073.3653066550746,
      "search_source": "rootcause:an interrupt occurring after incrementing qnodesp->count but before initializing node->lock can cause another CPU to read stale lock values from get_tail_qnode(). If this stale lock value matches the lock on the other CPU"
    },
    {
      "cwe_id": "362",
      "name": "Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition')",
      "score": 971.0937129779074,
      "search_source": "rootcause:an interrupt occurring after incrementing qnodesp->count but before initializing node->lock can cause another CPU to read stale lock values from get_tail_qnode(). If this stale lock value matches the lock on the other CPU"
    },
    {
      "cwe_id": "451",
      "name": "User Interface (UI) Misrepresentation of Critical Information",
      "score": 968.0917186040554,
      "search_source": "rootcause:an interrupt occurring after incrementing qnodesp->count but before initializing node->lock can cause another CPU to read stale lock values from get_tail_qnode(). If this stale lock value matches the lock on the other CPU"
    },
    {
      "cwe_id": "835",
      "name": "Loop with Unreachable Exit Condition ('Infinite Loop')",
      "score": 958.0268658469913,
      "search_source": "rootcause:an interrupt occurring after incrementing qnodesp->count but before initializing node->lock can cause another CPU to read stale lock values from get_tail_qnode(). If this stale lock value matches the lock on the other CPU"
    },
    {
      "cwe_id": "1390",
      "name": "Weak Authentication",
      "score": 948.7712036545865,
      "search_source": "rootcause:an interrupt occurring after incrementing qnodesp->count but before initializing node->lock can cause another CPU to read stale lock values from get_tail_qnode(). If this stale lock value matches the lock on the other CPU"
    },
    {
      "cwe_id": "319",
      "name": "Cleartext Transmission of Sensitive Information",
      "score": 938.3111377427825,
      "search_source": "rootcause:an interrupt occurring after incrementing qnodesp->count but before initializing node->lock can cause another CPU to read stale lock values from get_tail_qnode(). If this stale lock value matches the lock on the other CPU"
    },
    {
      "cwe_id": "400",
      "name": "Uncontrolled Resource Consumption",
      "score": 926.561911758671,
      "search_source": "rootcause:an interrupt occurring after incrementing qnodesp->count but before initializing node->lock can cause another CPU to read stale lock values from get_tail_qnode(). If this stale lock value matches the lock on the other CPU"
    },
    {
      "cwe_id": "770",
      "name": "Allocation of Resources Without Limits or Throttling",
      "score": 916.7563599150362,
      "search_source": "rootcause:an interrupt occurring after incrementing qnodesp->count but before initializing node->lock can cause another CPU to read stale lock values from get_tail_qnode(). If this stale lock value matches the lock on the other CPU"
    },
    {
      "cwe_id": "1284",
      "name": "Improper Validation of Specified Quantity in Input",
      "score": 914.8130895541417,
      "search_source": "rootcause:an interrupt occurring after incrementing qnodesp->count but before initializing node->lock can cause another CPU to read stale lock values from get_tail_qnode(). If this stale lock value matches the lock on the other CPU"
    },
    {
      "cwe_id": "119",
      "name": "Improper Restriction of Operations within the Bounds of a Memory Buffer",
      "score": 797.6585629618032,
      "search_source": "weakness:Race condition due to the lack of proper synchronization between incrementing the qnodesp->count"
    },
    {
      "cwe_id": "364",
      "name": "Signal Handler Race Condition",
      "score": 796.7738375718938,
      "search_source": "weakness:Race condition due to the lack of proper synchronization between incrementing the qnodesp->count"
    }
  ]
}