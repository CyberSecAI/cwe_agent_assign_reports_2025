{
  "method": "sparse_altterm_rootcause_prompt inj",
  "query": "Monica AI Assistant desktop application v2.3.0 is vulnerable to Exposure of Sensitive Information to an Unauthorized Actor. A prompt injection allows an attacker to modify chatbot answer with an unloaded image that exfiltrates the users sensitive chat data of the current session to a malicious third-party or attacker-controlled server.",
  "keyphrases": {
    "rootcause": "prompt injection"
  },
  "timestamp": "2025-07-12T04:40:32.165702",
  "results_count": 1,
  "results_summary": [
    {
      "doc_id": "1427",
      "name": "Improper Neutralization of Input Used for LLM Prompting",
      "score": 1000.0
    }
  ]
}