{
  "retriever": "graph",
  "query": "In the Linux kernel, the following vulnerability has been resolved rcu/nocb Fix missed RCU barrier on deoffloading Currently, running rcutorture test with torture_type=rcu fwd_progress=8 n_barrier_cbs=8 nocbs_nthreads=8 nocbs_toggle=100 onoff_interval=60 test_boost=2, will trigger the following warning WARNING CPU 19 PID 100 at kernel/rcu/tree_nocb.h1061 rcu_nocb_rdp_deoffload+0x292/0x2a0 RIP 0010rcu_nocb_rdp_deoffload+0x292/0x2a0 Call Trace ? __warn+0x7e/0x120 ? rcu_nocb_rdp_deoffload+0x292/0x2a0 ? report_bug+0x18e/0x1a0 ? handle_bug+0x3d/0x70 ? exc_invalid_op+0x18/0x70 ? asm_exc_invalid_op+0x1a/0x20 ? rcu_nocb_rdp_deoffload+0x292/0x2a0 rcu_nocb_cpu_deoffload+0x70/0xa0 rcu_nocb_toggle+0x136/0x1c0 ? __pfx_rcu_nocb_toggle+0x10/0x10 kthread+0xd1/0x100 ? __pfx_kthread+0x10/0x10 ret_from_fork+0x2f/0x50 ? __pfx_kthread+0x10/0x10 ret_from_fork_asm+0x1a/0x30 CPU0 CPU2 CPU3 //rcu_nocb_toggle //nocb_cb_wait //rcutorture // deoffload CPU1 // process CPU1s rdp rcu_barrier() rcu_segcblist_entrain() rcu_segcblist_add_len(1) // len == 2 // enqueue barrier // callback to CPU1s // rdp->cblist rcu_do_batch() // invoke CPU1s rdp->cblist // callback rcu_barrier_callback() rcu_barrier() mutex_lock(&rcu_state.barrier_mutex) // still see len == 2 // enqueue barrier callback // to CPU1s rdp->cblist rcu_segcblist_entrain() rcu_segcblist_add_len(1) // len == 3 // decrement len rcu_segcblist_add_len(-2) kthread_parkme() // CPU1s rdp->cblist len == 1 // Warn because there is // still a pending barrier // trigger warning WARN_ON_ONCE(rcu_segcblist_n_cbs(&rdp->cblist)) cpus_read_unlock() // wait CPU1 to comes online and // invoke barrier callback on // CPU1 rdps->cblist wait_for_completion(&rcu_state.barrier_completion) // deoffload CPU4 cpus_read_lock() rcu_barrier() mutex_lock(&rcu_state.barrier_mutex) // block on barrier_mutex // wait rcu_barrier() on // CPU3 to unlock barrier_mutex // but CPU3 unlock barrier_mutex // need to wait CPU1 comes online // when CPU1 going online will block on cpus_write_lock The above scenario will not only trigger a WARN_ON_ONCE(), but also trigger a deadlock. Thanks to nocb locking, a second racing rcu_barrier() on an offline CPU will either observe the decremented callback counter down to 0 and spare the callback enqueue, or rcuo will observe the new callback and keep rdp->nocb_cb_sleep to false. Therefore check rdp->nocb_cb_sleep before parking to make sure no further rcu_barrier() is waiting on the rdp. Consider specifically these CWEs: CWE-1390 CWE-230 CWE-1284 CWE-911 CWE-400 CWE-775 CWE-667 CWE-833 CWE-413 CWE-362",
  "keyphrases": {
    "original_query": "In the Linux kernel, the following vulnerability has been resolved rcu/nocb Fix missed RCU barrier on deoffloading Currently, running rcutorture test with torture_type=rcu fwd_progress=8 n_barrier_cbs=8 nocbs_nthreads=8 nocbs_toggle=100 onoff_interval=60 test_boost=2, will trigger the following warning WARNING CPU 19 PID 100 at kernel/rcu/tree_nocb.h1061 rcu_nocb_rdp_deoffload+0x292/0x2a0 RIP 0010rcu_nocb_rdp_deoffload+0x292/0x2a0 Call Trace ? __warn+0x7e/0x120 ? rcu_nocb_rdp_deoffload+0x292/0x2a0 ? report_bug+0x18e/0x1a0 ? handle_bug+0x3d/0x70 ? exc_invalid_op+0x18/0x70 ? asm_exc_invalid_op+0x1a/0x20 ? rcu_nocb_rdp_deoffload+0x292/0x2a0 rcu_nocb_cpu_deoffload+0x70/0xa0 rcu_nocb_toggle+0x136/0x1c0 ? __pfx_rcu_nocb_toggle+0x10/0x10 kthread+0xd1/0x100 ? __pfx_kthread+0x10/0x10 ret_from_fork+0x2f/0x50 ? __pfx_kthread+0x10/0x10 ret_from_fork_asm+0x1a/0x30 CPU0 CPU2 CPU3 //rcu_nocb_toggle //nocb_cb_wait //rcutorture // deoffload CPU1 // process CPU1s rdp rcu_barrier() rcu_segcblist_entrain() rcu_segcblist_add_len(1) // len == 2 // enqueue barrier // callback to CPU1s // rdp->cblist rcu_do_batch() // invoke CPU1s rdp->cblist // callback rcu_barrier_callback() rcu_barrier() mutex_lock(&rcu_state.barrier_mutex) // still see len == 2 // enqueue barrier callback // to CPU1s rdp->cblist rcu_segcblist_entrain() rcu_segcblist_add_len(1) // len == 3 // decrement len rcu_segcblist_add_len(-2) kthread_parkme() // CPU1s rdp->cblist len == 1 // Warn because there is // still a pending barrier // trigger warning WARN_ON_ONCE(rcu_segcblist_n_cbs(&rdp->cblist)) cpus_read_unlock() // wait CPU1 to comes online and // invoke barrier callback on // CPU1 rdps->cblist wait_for_completion(&rcu_state.barrier_completion) // deoffload CPU4 cpus_read_lock() rcu_barrier() mutex_lock(&rcu_state.barrier_mutex) // block on barrier_mutex // wait rcu_barrier() on // CPU3 to unlock barrier_mutex // but CPU3 unlock barrier_mutex // need to wait CPU1 comes online // when CPU1 going online will block on cpus_write_lock The above scenario will not only trigger a WARN_ON_ONCE(), but also trigger a deadlock. Thanks to nocb locking, a second racing rcu_barrier() on an offline CPU will either observe the decremented callback counter down to 0 and spare the callback enqueue, or rcuo will observe the new callback and keep rdp->nocb_cb_sleep to false. Therefore check rdp->nocb_cb_sleep before parking to make sure no further rcu_barrier() is waiting on the rdp.",
    "enhanced_query": "In the Linux kernel, the following vulnerability has been resolved rcu/nocb Fix missed RCU barrier on deoffloading Currently, running rcutorture test with torture_type=rcu fwd_progress=8 n_barrier_cbs=8 nocbs_nthreads=8 nocbs_toggle=100 onoff_interval=60 test_boost=2, will trigger the following warning WARNING CPU 19 PID 100 at kernel/rcu/tree_nocb.h1061 rcu_nocb_rdp_deoffload+0x292/0x2a0 RIP 0010rcu_nocb_rdp_deoffload+0x292/0x2a0 Call Trace ? __warn+0x7e/0x120 ? rcu_nocb_rdp_deoffload+0x292/0x2a0 ? report_bug+0x18e/0x1a0 ? handle_bug+0x3d/0x70 ? exc_invalid_op+0x18/0x70 ? asm_exc_invalid_op+0x1a/0x20 ? rcu_nocb_rdp_deoffload+0x292/0x2a0 rcu_nocb_cpu_deoffload+0x70/0xa0 rcu_nocb_toggle+0x136/0x1c0 ? __pfx_rcu_nocb_toggle+0x10/0x10 kthread+0xd1/0x100 ? __pfx_kthread+0x10/0x10 ret_from_fork+0x2f/0x50 ? __pfx_kthread+0x10/0x10 ret_from_fork_asm+0x1a/0x30 CPU0 CPU2 CPU3 //rcu_nocb_toggle //nocb_cb_wait //rcutorture // deoffload CPU1 // process CPU1s rdp rcu_barrier() rcu_segcblist_entrain() rcu_segcblist_add_len(1) // len == 2 // enqueue barrier // callback to CPU1s // rdp->cblist rcu_do_batch() // invoke CPU1s rdp->cblist // callback rcu_barrier_callback() rcu_barrier() mutex_lock(&rcu_state.barrier_mutex) // still see len == 2 // enqueue barrier callback // to CPU1s rdp->cblist rcu_segcblist_entrain() rcu_segcblist_add_len(1) // len == 3 // decrement len rcu_segcblist_add_len(-2) kthread_parkme() // CPU1s rdp->cblist len == 1 // Warn because there is // still a pending barrier // trigger warning WARN_ON_ONCE(rcu_segcblist_n_cbs(&rdp->cblist)) cpus_read_unlock() // wait CPU1 to comes online and // invoke barrier callback on // CPU1 rdps->cblist wait_for_completion(&rcu_state.barrier_completion) // deoffload CPU4 cpus_read_lock() rcu_barrier() mutex_lock(&rcu_state.barrier_mutex) // block on barrier_mutex // wait rcu_barrier() on // CPU3 to unlock barrier_mutex // but CPU3 unlock barrier_mutex // need to wait CPU1 comes online // when CPU1 going online will block on cpus_write_lock The above scenario will not only trigger a WARN_ON_ONCE(), but also trigger a deadlock. Thanks to nocb locking, a second racing rcu_barrier() on an offline CPU will either observe the decremented callback counter down to 0 and spare the callback enqueue, or rcuo will observe the new callback and keep rdp->nocb_cb_sleep to false. Therefore check rdp->nocb_cb_sleep before parking to make sure no further rcu_barrier() is waiting on the rdp. Consider specifically these CWEs: CWE-1390 CWE-230 CWE-1284 CWE-911 CWE-400 CWE-775 CWE-667 CWE-833 CWE-413 CWE-362",
    "cwe_mentions": [
      "CWE-1390",
      "CWE-230",
      "CWE-1284",
      "CWE-911",
      "CWE-400",
      "CWE-775",
      "CWE-667",
      "CWE-833",
      "CWE-413",
      "CWE-362"
    ],
    "search_time": 3.218892812728882
  },
  "timestamp": "2025-07-13 23:49:26",
  "cve_id": "CVE-2024-56547",
  "result_count": 20,
  "results": [
    {
      "cwe_id": "364",
      "name": "Signal Handler Race Condition",
      "type": "base",
      "score": 2.3400000000000003,
      "relationship_count": 0
    },
    {
      "cwe_id": "772",
      "name": "Missing Release of Resource after Effective Lifetime",
      "type": "base",
      "score": 2.2100000000000004,
      "relationship_count": 0
    },
    {
      "cwe_id": "410",
      "name": "Insufficient Resource Pool",
      "type": "base",
      "score": 2.2100000000000004,
      "relationship_count": 0
    },
    {
      "cwe_id": "416",
      "name": "Use After Free",
      "type": "variant",
      "score": 2.04,
      "relationship_count": 0
    },
    {
      "cwe_id": "1284",
      "name": "Improper Validation of Specified Quantity in Input",
      "type": "Base",
      "score": 1.9525478256224744,
      "relationship_count": 0
    },
    {
      "cwe_id": "120",
      "name": "Buffer Copy without Checking Size of Input ('Classic Buffer Overflow')",
      "type": "base",
      "score": 1.7680000000000005,
      "relationship_count": 0
    },
    {
      "cwe_id": "123",
      "name": "Write-what-where Condition",
      "type": "base",
      "score": 1.7680000000000005,
      "relationship_count": 0
    },
    {
      "cwe_id": "789",
      "name": "Memory Allocation with Excessive Size Value",
      "type": "Variant",
      "score": 1.7248606823851822,
      "relationship_count": 0
    },
    {
      "cwe_id": "833",
      "name": "Deadlock",
      "type": "Base",
      "score": 1.7112404330422895,
      "relationship_count": 0
    },
    {
      "cwe_id": "413",
      "name": "Improper Resource Locking",
      "type": "Base",
      "score": 1.694530947767081,
      "relationship_count": 0
    },
    {
      "cwe_id": "826",
      "name": "Premature Release of Resource During Expected Lifetime",
      "type": "base",
      "score": 1.6848000000000003,
      "relationship_count": 0
    },
    {
      "cwe_id": "562",
      "name": "Return of Stack Variable Address",
      "type": "base",
      "score": 1.6848000000000003,
      "relationship_count": 0
    },
    {
      "cwe_id": "1341",
      "name": "Multiple Releases of Same Resource or Handle",
      "type": "base",
      "score": 1.6848000000000003,
      "relationship_count": 0
    },
    {
      "cwe_id": "1265",
      "name": "Unintended Reentrant Invocation of Non-reentrant Code Via Nested Calls",
      "type": "base",
      "score": 1.6848000000000003,
      "relationship_count": 0
    },
    {
      "cwe_id": "386",
      "name": "Symbolic Name not Mapping to Correct Object",
      "type": "base",
      "score": 1.6744000000000003,
      "relationship_count": 0
    },
    {
      "cwe_id": "662",
      "name": "Improper Synchronization",
      "type": "class",
      "score": 1.6736000000000002,
      "relationship_count": 0
    },
    {
      "cwe_id": "61",
      "name": "UNIX Symbolic Link (Symlink) Following",
      "type": "compound",
      "score": 1.61,
      "relationship_count": 0
    },
    {
      "cwe_id": "129",
      "name": "Improper Validation of Array Index",
      "type": "variant",
      "score": 1.5552000000000004,
      "relationship_count": 0
    },
    {
      "cwe_id": "476",
      "name": "NULL Pointer Dereference",
      "type": "Base",
      "score": 1.5262546090454812,
      "relationship_count": 0
    },
    {
      "cwe_id": "1325",
      "name": "Improperly Controlled Sequential Memory Allocation",
      "type": "Base",
      "score": 1.5215403726443069,
      "relationship_count": 0
    }
  ]
}